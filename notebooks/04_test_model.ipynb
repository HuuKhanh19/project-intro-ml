{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39421d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n",
      "\n",
      "======================================================================\n",
      "üîç DEVICE INFORMATION\n",
      "======================================================================\n",
      "PyTorch version: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "CUDA version: 12.9\n",
      "GPU count: 2\n",
      "GPU name: NVIDIA GeForce RTX 5070 Ti\n",
      "GPU memory: 15.9 GB\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: Setup\n",
    "# ============================================================================\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from src.models import LeNet5, ResNet50, DenseNet121, VisionTransformer\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "\n",
    "# Check GPU\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç DEVICE INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Running on CPU\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94bbaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Helper functions\n",
    "# ============================================================================\n",
    "def test_model(model_class, model_name, num_classes=4, batch_size=2):\n",
    "    \"\"\"\n",
    "    Test a model with dummy input\n",
    "    \n",
    "    Args:\n",
    "        model_class: Model class to test\n",
    "        model_name: Name for display\n",
    "        num_classes: Number of output classes\n",
    "        batch_size: Batch size for testing\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"{model_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create model\n",
    "    if 'pretrained' in model_class.__init__.__code__.co_varnames:\n",
    "        model = model_class(num_classes=num_classes, pretrained=False)\n",
    "    else:\n",
    "        model = model_class(num_classes=num_classes)\n",
    "    \n",
    "    # Test input\n",
    "    dummy_input = torch.randn(batch_size, 3, 224, 224)\n",
    "    \n",
    "    # CPU forward pass\n",
    "    print(\"\\nüìä Model Info:\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"  Input shape:  {dummy_input.shape}\")\n",
    "        print(f\"  Output shape: {output.shape}\")\n",
    "        print(f\"  Total params: {total_params:,}\")\n",
    "        print(f\"  Trainable:    {trainable_params:,}\")\n",
    "        print(f\"  Model size:   ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ CPU test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå CPU test failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # GPU test if available\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            # Clear cache first\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Move to GPU\n",
    "            model_gpu = model.cuda()\n",
    "            input_gpu = dummy_input.cuda()\n",
    "            \n",
    "            # Warmup\n",
    "            with torch.no_grad():\n",
    "                _ = model_gpu(input_gpu)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            # Measure memory\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_gpu = model_gpu(input_gpu)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            peak_memory = torch.cuda.max_memory_allocated(0) / 1024**2\n",
    "            \n",
    "            print(f\"\\nüî• GPU test:\")\n",
    "            print(f\"  Peak memory: {peak_memory:.1f} MB\")\n",
    "            print(f\"  Per sample:  {peak_memory / batch_size:.1f} MB\")\n",
    "            print(f\"  ‚úÖ GPU test passed\")\n",
    "            \n",
    "            # Cleanup\n",
    "            del model_gpu, input_gpu, output_gpu\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  GPU test failed: {e}\")\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(f\"   ‚Üí Try reducing batch size\")\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, dummy_input\n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e70ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1. LeNet-5 (1998)\n",
      "======================================================================\n",
      "\n",
      "üìä Model Info:\n",
      "  Input shape:  torch.Size([4, 3, 224, 224])\n",
      "  Output shape: torch.Size([4, 4])\n",
      "  Total params: 5,612,216\n",
      "  Trainable:    5,612,216\n",
      "  Model size:   ~21.4 MB\n",
      "\n",
      "‚úÖ CPU test passed\n",
      "\n",
      "üî• GPU test:\n",
      "  Peak memory: 42.1 MB\n",
      "  Per sample:  10.5 MB\n",
      "  ‚úÖ GPU test passed\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Test LeNet-5\n",
    "# ============================================================================\n",
    "test_model(LeNet5, \"1. LeNet-5 (1998)\", num_classes=4, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b6d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2. ResNet-50 (2015)\n",
      "======================================================================\n",
      "\n",
      "üìä Model Info:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/chest-xray/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/chest-xray/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input shape:  torch.Size([4, 3, 224, 224])\n",
      "  Output shape: torch.Size([4, 4])\n",
      "  Total params: 23,516,228\n",
      "  Trainable:    23,516,228\n",
      "  Model size:   ~89.7 MB\n",
      "\n",
      "‚úÖ CPU test passed\n",
      "\n",
      "üî• GPU test:\n",
      "  Peak memory: 141.6 MB\n",
      "  Per sample:  35.4 MB\n",
      "  ‚úÖ GPU test passed\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: Test ResNet-50\n",
    "# ============================================================================\n",
    "test_model(ResNet50, \"2. ResNet-50 (2015)\", num_classes=4, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34479fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3. DenseNet-121 (2017)\n",
      "======================================================================\n",
      "\n",
      "üìä Model Info:\n",
      "  Input shape:  torch.Size([4, 3, 224, 224])\n",
      "  Output shape: torch.Size([4, 4])\n",
      "  Total params: 6,957,956\n",
      "  Trainable:    6,957,956\n",
      "  Model size:   ~26.5 MB\n",
      "\n",
      "‚úÖ CPU test passed\n",
      "\n",
      "üî• GPU test:\n",
      "  Peak memory: 76.9 MB\n",
      "  Per sample:  19.2 MB\n",
      "  ‚úÖ GPU test passed\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Test DenseNet-121\n",
    "# ============================================================================\n",
    "test_model(DenseNet121, \"3. DenseNet-121 (2017)\", num_classes=4, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510e25ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "4. Vision Transformer (2020)\n",
      "======================================================================\n",
      "\n",
      "üìä Model Info:\n",
      "  Input shape:  torch.Size([2, 3, 224, 224])\n",
      "  Output shape: torch.Size([2, 4])\n",
      "  Total params: 85,801,732\n",
      "  Trainable:    85,801,732\n",
      "  Model size:   ~327.3 MB\n",
      "\n",
      "‚úÖ CPU test passed\n",
      "\n",
      "üî• GPU test:\n",
      "  Peak memory: 355.3 MB\n",
      "  Per sample:  177.6 MB\n",
      "  ‚úÖ GPU test passed\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Test Vision Transformer\n",
    "# ============================================================================\n",
    "# ViT requires smaller batch due to memory\n",
    "test_model(VisionTransformer, \"4. Vision Transformer (2020)\", num_classes=4, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6647c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä MODEL COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "       Model  Year Parameters Size (MB) Pretrained\n",
      "     LeNet-5  1998  5,612,216      21.4          ‚ùå\n",
      "   ResNet-50  2015 23,516,228      89.7          ‚úÖ\n",
      "DenseNet-121  2017  6,957,956      26.5          ‚úÖ\n",
      "    ViT-Base  2020 85,801,732     327.3          ‚úÖ\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Model Comparison Summary\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models_info = {\n",
    "    'LeNet-5': (LeNet5, 1998, False),\n",
    "    'ResNet-50': (ResNet50, 2015, True),\n",
    "    'DenseNet-121': (DenseNet121, 2017, True),\n",
    "    'ViT-Base': (VisionTransformer, 2020, True),\n",
    "}\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for name, (model_class, year, pretrained) in models_info.items():\n",
    "    try:\n",
    "        # Create model without pretrained weights for fair comparison\n",
    "        if pretrained:\n",
    "            model = model_class(num_classes=4, pretrained=False)\n",
    "        else:\n",
    "            model = model_class(num_classes=4)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        model_size = total_params * 4 / 1024**2  # MB\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'Year': year,\n",
    "            'Parameters': f\"{total_params:,}\",\n",
    "            'Size (MB)': f\"{model_size:.1f}\",\n",
    "            'Pretrained': '‚úÖ' if pretrained else '‚ùå'\n",
    "        })\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error with {name}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4d2ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üèóÔ∏è  MODEL ARCHITECTURES\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£  LeNet-5:\n",
      "LeNet5(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=46656, out_features=120, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=84, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "2Ô∏è‚É£  ResNet-50 (simplified):\n",
      "\n",
      "ResNet50(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
      "    (bn1): BatchNorm2d(64)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (layer1): Bottleneck blocks x3\n",
      "    (layer2): Bottleneck blocks x4\n",
      "    (layer3): Bottleneck blocks x6\n",
      "    (layer4): Bottleneck blocks x3\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=4)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "3Ô∏è‚É£  DenseNet-121 (simplified):\n",
      "\n",
      "DenseNet121(\n",
      "  (model): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
      "      (norm0): BatchNorm2d(64)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
      "      (denseblock1-4): Dense blocks with growth_rate=32\n",
      "      (transition1-3): Transition layers\n",
      "    )\n",
      "    (classifier): Linear(in_features=1024, out_features=4)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "4Ô∏è‚É£  Vision Transformer (simplified):\n",
      "\n",
      "VisionTransformer(\n",
      "  (model): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=16, stride=16)\n",
      "    )\n",
      "    (cls_token): Parameter[1, 1, 768]\n",
      "    (pos_embed): Parameter[1, 197, 768]\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x TransformerBlock(\n",
      "        (attn): MultiheadAttention\n",
      "        (mlp): MLP\n",
      "        (norm1, norm2): LayerNorm\n",
      "      )\n",
      "    )\n",
      "    (head): Linear(in_features=768, out_features=4)\n",
      "  )\n",
      ")\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: Architecture Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèóÔ∏è  MODEL ARCHITECTURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  LeNet-5:\")\n",
    "model = LeNet5(num_classes=4)\n",
    "print(model)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"\\n2Ô∏è‚É£  ResNet-50 (simplified):\")\n",
    "print(\"\"\"\n",
    "ResNet50(\n",
    "  (model): ResNet(\n",
    "    (conv1): Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "    (bn1): BatchNorm2d(64)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    (layer1): Bottleneck blocks x3\n",
    "    (layer2): Bottleneck blocks x4\n",
    "    (layer3): Bottleneck blocks x6\n",
    "    (layer4): Bottleneck blocks x3\n",
    "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "    (fc): Linear(in_features=2048, out_features=4)\n",
    "  )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"\\n3Ô∏è‚É£  DenseNet-121 (simplified):\")\n",
    "print(\"\"\"\n",
    "DenseNet121(\n",
    "  (model): DenseNet(\n",
    "    (features): Sequential(\n",
    "      (conv0): Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "      (norm0): BatchNorm2d(64)\n",
    "      (relu0): ReLU(inplace=True)\n",
    "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "      (denseblock1-4): Dense blocks with growth_rate=32\n",
    "      (transition1-3): Transition layers\n",
    "    )\n",
    "    (classifier): Linear(in_features=1024, out_features=4)\n",
    "  )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"\\n4Ô∏è‚É£  Vision Transformer (simplified):\")\n",
    "print(\"\"\"\n",
    "VisionTransformer(\n",
    "  (model): VisionTransformer(\n",
    "    (patch_embed): PatchEmbed(\n",
    "      (proj): Conv2d(3, 768, kernel_size=16, stride=16)\n",
    "    )\n",
    "    (cls_token): Parameter[1, 1, 768]\n",
    "    (pos_embed): Parameter[1, 197, 768]\n",
    "    (blocks): ModuleList(\n",
    "      (0-11): 12 x TransformerBlock(\n",
    "        (attn): MultiheadAttention\n",
    "        (mlp): MLP\n",
    "        (norm1, norm2): LayerNorm\n",
    "      )\n",
    "    )\n",
    "    (head): Linear(in_features=768, out_features=4)\n",
    "  )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8b26fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üíæ MEMORY REQUIREMENTS ESTIMATION\n",
      "======================================================================\n",
      "\n",
      "Estimated GPU memory per batch (MB):\n",
      "Model                Batch=8      Batch=16     Batch=32     Batch=64    \n",
      "----------------------------------------------------------------------\n",
      "LeNet-5              84           168          336          673         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/chest-xray/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/chest-xray/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50            284          569          1138         2276        \n",
      "DenseNet-121         154          307          615          1230        \n",
      "ViT-Base             732          1464         2928         5857        \n",
      "\n",
      "======================================================================\n",
      "üí° Tips:\n",
      "  - Start with smaller batch sizes for larger models\n",
      "  - Use gradient accumulation if batch size is limited\n",
      "  - Monitor GPU memory during training\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: Memory Requirements Estimation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíæ MEMORY REQUIREMENTS ESTIMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64]\n",
    "models_to_test = {\n",
    "    'LeNet-5': LeNet5,\n",
    "    'ResNet-50': ResNet50,\n",
    "    'DenseNet-121': DenseNet121,\n",
    "    'ViT-Base': VisionTransformer\n",
    "}\n",
    "\n",
    "print(\"\\nEstimated GPU memory per batch (MB):\")\n",
    "print(f\"{'Model':<20} {'Batch=8':<12} {'Batch=16':<12} {'Batch=32':<12} {'Batch=64':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, model_class in models_to_test.items():\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            memory_usage = []\n",
    "            \n",
    "            for bs in batch_sizes:\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                \n",
    "                # Test with smaller batch if needed\n",
    "                test_bs = min(bs, 4)\n",
    "                \n",
    "                if 'pretrained' in model_class.__init__.__code__.co_varnames:\n",
    "                    model = model_class(num_classes=4, pretrained=False).cuda()\n",
    "                else:\n",
    "                    model = model_class(num_classes=4).cuda()\n",
    "                \n",
    "                dummy = torch.randn(test_bs, 3, 224, 224).cuda()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    _ = model(dummy)\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                \n",
    "                peak = torch.cuda.max_memory_allocated(0) / 1024**2\n",
    "                # Extrapolate for actual batch size\n",
    "                estimated = peak * (bs / test_bs)\n",
    "                memory_usage.append(f\"{estimated:.0f}\")\n",
    "                \n",
    "                del model, dummy\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            print(f\"{model_name:<20} {memory_usage[0]:<12} {memory_usage[1]:<12} {memory_usage[2]:<12} {memory_usage[3]:<12}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{model_name:<20} Error: {str(e)[:40]}\")\n",
    "    else:\n",
    "        print(f\"{model_name:<20} GPU not available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° Tips:\")\n",
    "print(\"  - Start with smaller batch sizes for larger models\")\n",
    "print(\"  - Use gradient accumulation if batch size is limited\")\n",
    "print(\"  - Monitor GPU memory during training\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80db8379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ö° SPEED BENCHMARK\n",
      "======================================================================\n",
      "\n",
      "Settings: batch_size=16, iterations=50\n",
      "\n",
      "Model                Time/batch (ms)      Throughput (img/s)  \n",
      "----------------------------------------------------------------------\n",
      "LeNet-5              1.41                 11312.6             \n",
      "ResNet-50            9.81                 1630.4              \n",
      "DenseNet-121         16.42                974.1               \n",
      "ViT-Base             29.95                534.2               \n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 10: Speed Benchmark (Optional)\n",
    "# ============================================================================\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚ö° SPEED BENCHMARK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    batch_size = 16\n",
    "    num_iterations = 50\n",
    "    \n",
    "    print(f\"\\nSettings: batch_size={batch_size}, iterations={num_iterations}\")\n",
    "    print(f\"\\n{'Model':<20} {'Time/batch (ms)':<20} {'Throughput (img/s)':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for model_name, model_class in models_to_test.items():\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if 'pretrained' in model_class.__init__.__code__.co_varnames:\n",
    "                model = model_class(num_classes=4, pretrained=False).cuda()\n",
    "            else:\n",
    "                model = model_class(num_classes=4).cuda()\n",
    "            \n",
    "            model.eval()\n",
    "            dummy = torch.randn(batch_size, 3, 224, 224).cuda()\n",
    "            \n",
    "            # Warmup\n",
    "            with torch.no_grad():\n",
    "                for _ in range(10):\n",
    "                    _ = model(dummy)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            # Benchmark\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(num_iterations):\n",
    "                    _ = model(dummy)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            time_per_batch = (elapsed / num_iterations) * 1000  # ms\n",
    "            throughput = (batch_size * num_iterations) / elapsed  # img/s\n",
    "            \n",
    "            print(f\"{model_name:<20} {time_per_batch:<20.2f} {throughput:<20.1f}\")\n",
    "            \n",
    "            del model, dummy\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{model_name:<20} Error: {str(e)[:40]}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  GPU not available - skipping speed benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297a0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ MODEL TESTING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìù Summary:\n",
      "  ‚úÖ All 4 models tested successfully\n",
      "  ‚úÖ CPU forward pass verified\n",
      "  ‚úÖ GPU compatibility verified\n",
      "  ‚úÖ GPU: NVIDIA GeForce RTX 5070 Ti\n",
      "\n",
      "üéØ Next steps:\n",
      "  1. Run 02b_balance_data.ipynb (if not done)\n",
      "  2. Run 03_test_dataloader.ipynb to verify data pipeline\n",
      "  3. Start training with 05_train_lenet.ipynb\n",
      "\n",
      "======================================================================\n",
      "üßπ Memory cleaned up\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 11: Final Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ MODEL TESTING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìù Summary:\")\n",
    "print(\"  ‚úÖ All 4 models tested successfully\")\n",
    "print(\"  ‚úÖ CPU forward pass verified\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"  ‚úÖ GPU compatibility verified\")\n",
    "    print(f\"  ‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  GPU not available (CPU only)\")\n",
    "\n",
    "print(\"\\nüéØ Next steps:\")\n",
    "print(\"  1. Run 02b_balance_data.ipynb (if not done)\")\n",
    "print(\"  2. Run 03_test_dataloader.ipynb to verify data pipeline\")\n",
    "print(\"  3. Start training with 05_train_lenet.ipynb\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Final cleanup\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(\"üßπ Memory cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest-xray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
